{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ISCCP CTD for Third Pole region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO :\n",
    "- define functions for data  \n",
    "* read in nc files and store in group wise dataframe \n",
    "* extract only locations > 3000 m  \n",
    "* search for CS families after date or location \n",
    "* create climatology based on read in on multiple monthly files \n",
    "* plot tracks \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dictionary with text output files from Fortran program \n",
    "dir='/media/juli/Elements/ISCCP CTD/TP_DATABASE/'\n",
    "txt_files={}\n",
    "keys=[]\n",
    "values=[]\n",
    "\n",
    "for year in np.arange(1995,2008,1):\n",
    "    for month in np.arange(1,13,1):\n",
    "        if month < 10:\n",
    "            keys.append(str(year)+'_0'+str(month))\n",
    "        else:\n",
    "            keys.append(str(year)+'_'+str(month))       \n",
    "    \n",
    "for k in keys:\n",
    "    values.append(dir+'CS_TP_'+str(k)+'.txt')\n",
    "    \n",
    "## populate dictionary with keys and values \n",
    "txt_files= dict(zip(keys, values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# properties of tracked CS families\n",
    "props= ['SAT','FAM','MAX_SIZE','MIN_TEMP','PIXL_<200','LIFE_HOURS','ELAPS_HOURS','YEAR','MONTH','DAY','GMT','CS_RADIUS_KM','CS_CENTER_LAT','CS_CENTER_LON','INCL_NORTH','CS_ECCEN','SQUARE_CORR','CON_FRAC',\n",
    " 'NR_CCinCS','CC_MAX_RADIUS','CC_MEAN_RADIUS','CC_CENTER_LAT','CC_CENTER_LON','TEMP_GRAD','CS_MEAN_TEMP','CS_MIN_TEMP','CC_MEAN_TEMP','STD_CS_TEMP','CC_WIND_DIRECT','CC_WIND_SPEED','CS_WIND_DIRECT','CS_WIND_SPEED','NON_OVRLAP','OVRLAP_%',\n",
    " 'FLAG','DIV_FLAG','ISCCP_INTERN','LW_FLAG','MIN_TAU','MAX_TAU','MIN_LAT','MAX_LAT','MIN_LON','MAX_LON']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "## This funtion reads in .txt files produced by the ISCCP CTD Fortran code and returns a pandas dataframe \n",
    "#\n",
    "\n",
    "def get_data(file, props):\n",
    "    act = 0 # activating variable to read in lines to df\n",
    "    cc_data = 0\n",
    "    nr_cols= 44   # nr. of columns\n",
    "    key= 'DATABASE'   # key word after which lines should be extracted \n",
    "    i= 0 # loop counter \n",
    "    if os.path.exists(file): # test whether file exists \n",
    "        \n",
    "        with open(file) as cc: \n",
    "            for line in cc:   # wrap pbar around object to display progress \n",
    "                i += 1 \n",
    "                if key in line: \n",
    "                    act = 1\n",
    "                    if not isinstance(cc_data, pd.DataFrame):  # control if dataframe not already exist, in order to read in more files \n",
    "                        cc_data= pd.DataFrame()  # create pandas dataframe  \n",
    "                        #headers= line.split()      # split string line into list for col headers\n",
    "                if act == 1:\n",
    "                    cols= line.split()\n",
    "                    if len(cols)== nr_cols and cols[1].isdigit():          \n",
    "                        for item in range(0, len(cols)): \n",
    "                            if cols[item].isdigit():\n",
    "                                cols[item] = int(cols[item])          \n",
    "                        cc_data= cc_data.append([cols])          \n",
    "                if '===' in line: \n",
    "                    act = 0   \n",
    "                #if i%1000==0:   # track progress \n",
    "                #    print(i)\n",
    "                \n",
    "                \n",
    "                \n",
    "        cc_data.columns= props   # set column names\n",
    "        cc_data= cc_data.set_index(np.arange(1,cc_data.shape[0]+1)) # set row labels (dataframe index)\n",
    "        return cc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# This function redefines the data types used for the different variables in nc file \n",
    "# \n",
    "\n",
    "def define_dtypes(cc_data):\n",
    "\n",
    "    for i in props[1:43]:\n",
    "        cc_data[i]= pd.to_numeric(cc_data[i], downcast= 'integer') # change datatype of columns (except SAT )\n",
    "        cc_data.loc[cc_data[str(i)] == -99.0,str(i)] = np.nan # replace fill values with NaN \n",
    "    \n",
    "    # change float to integer for some cols\n",
    "    cc_data.FAM = cc_data.FAM.astype(int)\n",
    "    cc_data.YEAR = cc_data.YEAR.astype(int)\n",
    "    cc_data.MONTH = cc_data.MONTH.astype(int)\n",
    "    cc_data.DAY = cc_data.DAY.astype(int)\n",
    "    cc_data.FLAG = cc_data.FLAG.astype(int)\n",
    "    cc_data.LW_FLAG = cc_data.LW_FLAG.astype(int)\n",
    "    cc_data.DIV_FLAG = cc_data.DIV_FLAG.astype(int)\n",
    "    cc_data.SAT = cc_data.SAT.astype(str)\n",
    "    \n",
    "    return cc_data\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/juli/Elements/ISCCP CTD/TP_DATABASE/CS_TP_1995_01.txt\n",
      "/media/juli/Elements/ISCCP CTD/TP_DATABASE/CS_TP_1995_02.txt\n"
     ]
    }
   ],
   "source": [
    "##### MAIN PROGRAM ############################\n",
    "\n",
    "for month, file in txt_files.items():\n",
    "    print(file)\n",
    "    cc_data= get_data(file, props)    \n",
    "    cc_data= define_dtypes(cc_data)\n",
    "    path = '/media/juli/Elements/ISCCP CTD/TP_DATABASE/ncfiles/'\n",
    "    data_as_xr= cc_data.to_xarray()\n",
    "    data_as_xr.to_netcdf(path + 'ISCCP_CTD_TP_' +  month +  '.nc', mode = 'w', format='NETCDF4', unlimited_dims=['FAM'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Tested to create NetCDF groups, but very inefficient --> more creation time and much larger file sizes! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# divide dataframe into groups based on CS families & write nc files for each group \n",
    "#\n",
    "\n",
    "\n",
    "fams = cc_data.groupby('FAM', axis= 'rows') # fams = group object for each CS family which can be used to apply functions \n",
    "path = '/media/juli/Elements/ISCCP CTD/TP_DATABASE/'\n",
    "nc_groups = [] # list which contains strings with all nc files for groups \n",
    "\n",
    "for index, row in fams:\n",
    "    #index is a tuple (family name)\n",
    "    #row is a new dataframe for each group \n",
    "    xarr = row.to_xarray()\n",
    "    file = path + str(index) + '.nc'\n",
    "    xarr.to_netcdf(file, format='NETCDF4', unlimited_dims=['FAM'])\n",
    "    nc_groups.append(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n"
     ]
    }
   ],
   "source": [
    "# Append groups to nc file \n",
    "i = 0 \n",
    "for file in nc_groups:\n",
    "    if i%10==0:\n",
    "        print(i)\n",
    "    data_as_xr.to_netcdf(output, format='NETCDF4', mode= 'a', group = file) \n",
    "    i += 1 \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "## xarray attributes \n",
    "#data_as_xr.dims\n",
    "#data_as_xr.data_vars\n",
    "#data_as_xr.coords\n",
    "\n",
    "# conditional statement on column value \n",
    "#np.shape(np.where(cc_data['PIXL_<200']>0))[1]\n",
    "\n",
    "\n",
    "# check datatypes: \n",
    "#cc_data.dtypes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
